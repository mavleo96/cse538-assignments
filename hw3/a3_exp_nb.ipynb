{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, re, collections, string\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import csv\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import heapq\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import transformers\n",
    "import datasets\n",
    "import sentence_transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoModelForCausalLM, RobertaTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.random.randint(0, 2, (1, 100)).reshape(-1)\n",
    "pred = np.random.randint(0, 2, (1, 100)).reshape(-1)\n",
    "# pred = np.full((1, 100), 0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"acc: {accuracy_score(true, pred):.3f}, f1: {f1_score(true, pred, average=\"macro\"):.3f}\n",
    "Yes: prec: {precision_score(true, pred, pos_label=1, zero_division=0):.3f}, recall: {recall_score(true, pred, pos_label=1, zero_division=0):.3f}, f1: {f1_score(true, pred, pos_label=1, zero_division=0):.3f}\n",
    "No: prec: {precision_score(true, pred, pos_label=0, zero_division=0):.3f}, recall: {recall_score(true, pred, pos_label=0, zero_division=0):.3f}, f1: {f1_score(true, pred, pos_label=0, zero_division=0):.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 500, 100)\n",
    "target = torch.randint(0, 500, (1, 100))\n",
    "F.cross_entropy(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.rand(3, 2, requires_grad=False)\n",
    "output = F.binary_cross_entropy(m(input), target, reduction='none')\n",
    "output, input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "outputs = torch.sigmoid(model(inputs))  # shape: [batch_size]\n",
    "loss = criterion(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dummy input: 3 samples, 1 output neuron (binary classification)\n",
    "logits = torch.tensor([[0.2], [1.0], [-1.0]], dtype=torch.float32)\n",
    "targets = torch.tensor([[0.0], [1.0], [0.0]], dtype=torch.float32)  # labels\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = torch.sigmoid(logits)\n",
    "\n",
    "# Use BCELoss\n",
    "bce_loss = nn.BCELoss()\n",
    "loss = bce_loss(probs, targets)\n",
    "\n",
    "print(f\"BCELoss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 500, 100)\n",
    "target = torch.tensor(torch.randint(0, 500, (1, 100))\n",
    "# F.cross_entropy(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parts I and II\n",
    "boolq_dataset = load_dataset('google/boolq')\n",
    "\n",
    "boolq_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = [1 if x[\"answer\"] else 0 for x in boolq_dataset[\"validation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, RobertaTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "# model = GPT2LMHeadModel.from_pretrained('distilgpt2').cuda()\n",
    "# model = AutoModelForCausalLM.from_pretrained('distilgpt2').cuda()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilroberta-base')#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head = nn.Sequential(\n",
    "    nn.Linear(model.lm_head.dense.in_features, 1),\n",
    "    nn.Sigmoid()\n",
    ")#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0, tokenizer.vocab_size, (5, 256)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.logits#[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0, 2, (1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolq2tensor(x, append_answer=False):\n",
    "    if append_answer:\n",
    "        return tokenizer.encode(f\"{x['passage']}.\\n{x['question']}?\\n{'yes' if x['answer'] else 'no'}\", return_tensors=\"pt\")\n",
    "    else:\n",
    "        return tokenizer.encode(f\"{x['passage']}.\\n{x['question']}?\\n\", return_tensors=\"pt\")\n",
    "# List is alright here for the moment since max token length is 1024 and the max in the dataset is 25\n",
    "val_set = [boolq2tensor(x) for x in boolq_dataset[\"validation\"]]\n",
    "train_set = [boolq2tensor(x, append_answer=True) for x in boolq_dataset[\"train\"]]\n",
    "train_set2 = [boolq2tensor(x) for x in boolq_dataset[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_len = pd.Series(val_set).apply(lambda x: x.shape[1])\n",
    "train_len = pd.Series(train_set).apply(lambda x: x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_len.hist(bins=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorlist2padded(tensorlist, length: int, pad_token_id: int, pad_strategy: str):\n",
    "    assert len(tensorlist) > 0\n",
    "    assert all(x.ndim == 2 for x in tensorlist)\n",
    "    assert all(x.shape[0] == 1 for x in tensorlist)\n",
    "    assert length > 0\n",
    "    assert pad_token_id is not None\n",
    "    assert pad_strategy in {\"left\", \"right\"}\n",
    "\n",
    "    for i, x in enumerate(tensorlist):\n",
    "        if x.shape[1] < length:\n",
    "            if pad_strategy == \"left\":\n",
    "                tensorlist[i] = torch.cat([torch.full((1, length - x.shape[1]), pad_token_id), x], dim=1)\n",
    "            else:\n",
    "                tensorlist[i] = torch.cat([x, torch.full((1, length - x.shape[1]), pad_token_id)], dim=1)\n",
    "        elif x.shape[1] > length:\n",
    "            if pad_strategy == \"left\":\n",
    "                tensorlist[i] = x[:, -length:]\n",
    "            else:\n",
    "                tensorlist[i] = x[:, :length]\n",
    "        else:\n",
    "            assert x.shape[1] == length\n",
    "\n",
    "    concat_tensor = torch.cat(tensorlist, dim=0)\n",
    "    return concat_tensor\n",
    "\n",
    "# val_tensor = tensorlist2padded(val_set, 200, tokenizer.unk_token_id, \"left\").cuda()\n",
    "# train_tensor = tensorlist2padded(train_set, 1024, tokenizer.unk_token_id, \"left\").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "# val_loader = DataLoader(val_tensor, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = []\n",
    "# for x in val_set:\n",
    "for x in tqdm.tqdm(val_set):\n",
    "    with torch.no_grad():\n",
    "        if x.shape[1] > 1024:\n",
    "            x = x[:, -1024:]\n",
    "        out = model(x.cuda()).logits\n",
    "        # labels_pred.extend(out[:, -1, [645, 3763]].argmax(dim=1).cpu().tolist())\n",
    "        labels_pred.extend(out[:, -1, [3919, 8505]].argmax(dim=1).cpu().tolist())\n",
    "\n",
    "# tokenizer.decode(out[:, -1, :].argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_pred = []\n",
    "# for x in val_loader:\n",
    "#     with torch.no_grad():\n",
    "#         out = model(x.cuda()).logits\n",
    "#         labels_pred.extend(out[:, -1, [645, 3763]].argmax(dim=1).cpu().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if x['answer'] else 0 for x in boolq_dataset[\"validation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(labels_pred), Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode([\"no\", \"yes\"]) -> [3919, 8505]\n",
    "output_stacked = torch.stack(outputs)[:, [645, 3763]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1 if x['answer'] else 0 for x in boolq_dataset[\"validation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = output_stacked.argmax(dim=1)\n",
    "label_pred = label_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Overall: acc: {accuracy_score(labels, label_pred):.3f}, f1: {f1_score(labels, label_pred):.3f}\n",
    "    Yes: prec: {precision_score(labels, label_pred, pos_label=1):.3f}, recall: {recall_score(labels, label_pred, pos_label=1):.3f}, f1: {f1_score(labels, label_pred, pos_label=1):.3f}\n",
    "     No: prec: {precision_score(labels, label_pred, pos_label=0):.3f}, recall: {recall_score(labels, label_pred, pos_label=0):.3f}, f1: {f1_score(labels, label_pred, pos_label=0):.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.SPECIAL_TOKENS_ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distilroberta_rand():\n",
    "    model = AutoModelForCausalLM.from_pretrained('distilroberta-base')\n",
    "    for name, module in model.named_modules():\n",
    "        # TODO: check if this is correct or this is to be done for all layers\n",
    "        if \"roberta.encoder.layer.4\" in name or \"roberta.encoder.layer.5\" in name:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight)\n",
    "                nn.init.normal_(module.bias)\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distilroberta_kqv():\n",
    "    model = AutoModelForCausalLM.from_pretrained('distilroberta-base')\n",
    "    for name, module in model.named_modules():\n",
    "        if name in {\"roberta.encoder.layer.4\", \"roberta.encoder.layer.5\"}:\n",
    "            w = (module.attention.self.key.weight + module.attention.self.query.weight) / 2\n",
    "            b = (module.attention.self.key.bias + module.attention.self.query.bias) / 2\n",
    "            shared_linear_layer = nn.Linear(w.shape[1], w.shape[0])\n",
    "            with torch.no_grad():\n",
    "                shared_linear_layer.weight.copy_(w)\n",
    "                shared_linear_layer.bias.copy_(b)\n",
    "            module.attention.self.key = shared_linear_layer\n",
    "            module.attention.self.query = shared_linear_layer\n",
    "            module.attention.self.value = shared_linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from transformers.models.bert.modeling_bert.BertOutput\n",
    "class RobertaOutputNoRes(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class RobertaSelfOutputNoRes(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "def get_distilroberta_nores():\n",
    "    model = AutoModelForCausalLM.from_pretrained('distilroberta-base')\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if name in {\"roberta.encoder.layer.4\", \"roberta.encoder.layer.5\"}:\n",
    "            nores_self_output = RobertaSelfOutputNoRes(model.config)\n",
    "            nores_output = RobertaOutputNoRes(model.config)\n",
    "\n",
    "            nores_self_output.load_state_dict(module.attention.output.state_dict())\n",
    "            nores_output.load_state_dict(module.output.state_dict())\n",
    "\n",
    "            module.attention.output = nores_self_output\n",
    "            module.output = nores_output\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "model3 = get_distilroberta_nores().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0, tokenizer.vocab_size, (5, 256)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 50265])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(input).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse538",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
